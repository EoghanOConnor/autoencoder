{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYgfXFDhsXOs"
   },
   "source": [
    "# E-tivity 1 (23/01/23 - 05/02/23)\n",
    "\n",
    "* Your Name: Eoghan O'Connor\n",
    "\n",
    "* Your Student ID: 16110625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGjGasNMsXOy"
   },
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "### Context\n",
    "We have a mystery dataset. There are 9 explanatory variables and one response variable. The response variable is the last column and indicates if the sample is anomalous (=1, valid =0). The dataset is provided \"data.csv\". \n",
    "\n",
    "Of course in this case we could use supervised learning to generate a model and detect anomalies in new data. However the focus is on autoencoders, anomaly detection is just one of the potential uses for autoencoders.\n",
    "\n",
    "So we are going to pretend that we do not know which data are anomalous but we do know that the anomaly rate is small. Use an autoencoder to detect anomalies in the data. The correctness of the model can of course be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfIpAID6sXO0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRKH1KzPsXO1"
   },
   "source": [
    "### Guidelines\n",
    "\n",
    "The e-tivity is split into four tasks. The first three are \"group\" excersises, in that you post the solutions to Tasks 1-3 to a site. This will allow the members of your group to send you feedback (via the forums) so you can improve your submission. The final task is an individual task and together with the other tasks, should be uploaded to Sulis but not to gitlab. \n",
    "\n",
    "Marks will be deducted if task 4 is posted to gitlab in contravention of instructions. Also if the the final submission is not a single notebook with tasks 1-4 and with correct identification or filename.\n",
    "\n",
    "Grading guidelines: the scores for each task are additive, max 20. Weight [5/7]\n",
    "\n",
    "**Task 1 [0-6]**: perform and explain the steps taken in data pre-processing for this unsupervised learning model.\n",
    "\n",
    "**Task 2 [0-4]**: correctly train model to convergence with a suitable topology and 2 encoded variables.\n",
    "\n",
    "**Task 3 [0-4]**: select and explain choice of threshold for determining the anomalous data.\n",
    "\n",
    "**Task 4 [0-6]**: implement a suitable VAE with correct testing and not uploaded to gitlab, in contravention of the instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzGwqG8msXO2"
   },
   "source": [
    "## Problem\n",
    "\n",
    "If you train even a modest feed forward network via supervised learning you can get extremely good recall and precision, despite the unbalanced dataset. However in this e-tivity you will determining the anomalies by using an autoencoder. That is you will **not** be using the Anom flag to guide the training.\n",
    "\n",
    "The mystery dataset is available from the Sulis site, download the csv file and use it as the input data.\n",
    "\n",
    "### Tasks 1-3 (complete by Monday 30/01/23)\n",
    "\n",
    "These tasks are to be completed and uploaded to GitLab on which the other group members can comment. The forum activity will form part of the overall mark for the e-tivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZTgnw3PsXO3"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Load the module we need\n",
    "# Note that we are import the Keras backend, which is assumed to be Tensorflow\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Conv1DTranspose, Dropout, Flatten\n",
    "from tensorflow.keras.layers import UpSampling1D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.losses import mean_squared_error, binary_crossentropy, mse, KLDivergence\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "VvFo1Wvws9DA",
    "outputId": "ffcfbb48-2f63-4afc-d9a5-29ce7196b939"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-63643395-2818-41c3-a6f8-c99506937a18\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-63643395-2818-41c3-a6f8-c99506937a18\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data.csv to data (3).csv\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRvQxSWqsXO6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8-AHZ_RsXO7"
   },
   "source": [
    "**Task 1: data preprocessing**\n",
    "\n",
    "Explain any preprocessing steps you take and also how you have selected the training and test sets. Remember we do not know which samples are anomalous only that there are a small number of them compared to the total sample size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDeAj9QC-SWN"
   },
   "source": [
    "### **Notes**\n",
    "For Processing, 1st the data is checked or displayed.\n",
    "No NaN or Null values in dataset so the data is prepped for splitting.\n",
    "Rescaled using MinMaxScalar to return values between 0-1.\n",
    "After the data is split keeping an equal share of Anom between datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IuDD9hmzsXO8",
    "outputId": "e9b75771-69e6-4d8e-8a70-ae891c5d269a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   V1  V2  V3  V4  V5  V6  V7  V8  V9  Anom\n",
      "0  50  21  77   0  28   0  27  48  22     1\n",
      "1  53   0  82   0  52  -5  29  30   2     0\n",
      "2  37   0  76   0  28  18  40  48   8     0\n",
      "3  37   0  79   0  34 -26  43  46   2     0\n",
      "4  85   0  88  -4   6   1   3  83  80     1\n"
     ]
    }
   ],
   "source": [
    "# Checking data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8BrXLuZsXO9",
    "outputId": "e9eed7b7-c029-49d0-937f-fedc30dbcfb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'Anom'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0sXub68sXO-",
    "outputId": "7d27ec94-3557-4aeb-b7a3-6b44c61f02d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1      0\n",
       "V2      0\n",
       "V3      0\n",
       "V4      0\n",
       "V5      0\n",
       "V6      0\n",
       "V7      0\n",
       "V8      0\n",
       "V9      0\n",
       "Anom    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No null values found\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "FR0ERphesXO-",
    "outputId": "dbe4fab6-5e72-4040-c01c-2eb0c79b17cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fdfe0017-3d5a-4526-9bab-1ac33656cbb2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>Anom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "      <td>49097.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.932399</td>\n",
       "      <td>-0.063955</td>\n",
       "      <td>85.123124</td>\n",
       "      <td>0.213231</td>\n",
       "      <td>36.871784</td>\n",
       "      <td>2.160030</td>\n",
       "      <td>38.200725</td>\n",
       "      <td>48.288592</td>\n",
       "      <td>10.261930</td>\n",
       "      <td>0.071511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.875159</td>\n",
       "      <td>84.674481</td>\n",
       "      <td>8.877517</td>\n",
       "      <td>37.579171</td>\n",
       "      <td>19.963113</td>\n",
       "      <td>218.324964</td>\n",
       "      <td>13.446306</td>\n",
       "      <td>20.572064</td>\n",
       "      <td>23.751024</td>\n",
       "      <td>0.257680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>-4821.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-3939.000000</td>\n",
       "      <td>-188.000000</td>\n",
       "      <td>-26739.000000</td>\n",
       "      <td>-48.000000</td>\n",
       "      <td>-353.000000</td>\n",
       "      <td>-356.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>5075.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>3830.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>15164.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdfe0017-3d5a-4526-9bab-1ac33656cbb2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fdfe0017-3d5a-4526-9bab-1ac33656cbb2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fdfe0017-3d5a-4526-9bab-1ac33656cbb2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  49097.000000  49097.000000  49097.000000  49097.000000  49097.000000   \n",
       "mean      46.932399     -0.063955     85.123124      0.213231     36.871784   \n",
       "std       12.875159     84.674481      8.877517     37.579171     19.963113   \n",
       "min       27.000000  -4821.000000     21.000000  -3939.000000   -188.000000   \n",
       "25%       37.000000      0.000000     79.000000      0.000000     30.000000   \n",
       "50%       44.000000      0.000000     83.000000      0.000000     42.000000   \n",
       "75%       50.000000      0.000000     88.000000      0.000000     46.000000   \n",
       "max      126.000000   5075.000000    149.000000   3830.000000    436.000000   \n",
       "\n",
       "                 V6            V7            V8            V9          Anom  \n",
       "count  49097.000000  49097.000000  49097.000000  49097.000000  49097.000000  \n",
       "mean       2.160030     38.200725     48.288592     10.261930      0.071511  \n",
       "std      218.324964     13.446306     20.572064     23.751024      0.257680  \n",
       "min   -26739.000000    -48.000000   -353.000000   -356.000000      0.000000  \n",
       "25%       -4.000000     33.000000     35.000000      0.000000      0.000000  \n",
       "50%        0.000000     39.000000     41.000000      2.000000      0.000000  \n",
       "75%        5.000000     43.000000     55.000000      6.000000      0.000000  \n",
       "max    15164.000000    105.000000    270.000000    266.000000      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Values vary from -negative to +positive values Scalar\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZWT91MXvDeF"
   },
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the data\n",
    "scaler.fit(df)\n",
    "\n",
    "# Transform the data\n",
    "df_scaled = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23jlB2Bw0Kj5"
   },
   "outputs": [],
   "source": [
    "# Assign the features and labels\n",
    "X = df_scaled[:, :-1]  # select all rows and all columns except the last one\n",
    "y = df_scaled[:, -1]   # select all rows and the last column\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNoIEUzssXPA"
   },
   "source": [
    "**Task 2: model generation and training**\n",
    "\n",
    "Generate a suitable autoencoder model, the only restriction is that there should be only 2 latent variables. Train the model to a satistifactory result. Be aware that it will be much harder to achieve the sort of result you can get from a supervised learning model. \n",
    "\n",
    "**Hint**: it should not take longer than a 1000 epochs to train. However it may be difficult to train. Use different optimizers, topologies and/or weight initialisations to get convergence. Remember that achieving a perfect error means that the model will also be good at reconstructing anomalies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YB-XVRXd3XLf"
   },
   "source": [
    "### **Notes**\n",
    "Below the Autoencoder has 3 layers.\n",
    "Large dense layers worked best as small layers tended towards 0\n",
    "I will try introduce early stop but looking at the losses this model will stop early after 2-3 epochs.\n",
    "\n",
    "Dense layers were used as the data was Tabular rather than spatial (ideal for Conv)  \n",
    "Relu was used throughout the model bar the last layer in the decoder. Relu reduces the dimensionality of the input data to a latent space of 2, and helps the encoder learn a compressed representation of the data by setting negative values to 0.\n",
    "To reconstruct the input data a linear activation function was used as the input data had a wide range of values and a linear activation allows for this.\n",
    "Maybe a sigmoid or tanh might work here too??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4At-xJ1U03WG",
    "outputId": "5210f952-779c-443d-f188-2b4b3b76e4b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoded\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                640       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,786\n",
      "Trainable params: 2,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoded\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                192       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 9)                 585       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 777\n",
      "Trainable params: 777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " encoded (Functional)           (None, 2)            2786        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " decoded (Functional)           (None, 9)            777         ['encoded[0][0]']                \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor (TFOpLamb  (None, 9)           0           ['decoded[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 9)            0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.squared_difference (TF  (None, 9)           0           ['tf.convert_to_tensor[0][0]',   \n",
      " OpLambda)                                                        'tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None,)             0           ['tf.math.squared_difference[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  ()                  0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.size (TFOpLambda)  ()                  0           ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  ()                  0           ['tf.math.reduce_sum[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         ()                   0           ['tf.compat.v1.size[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.divide_no_nan (TFOpLam  ()                  0           ['tf.math.reduce_sum_1[0][0]',   \n",
      " bda)                                                             'tf.cast_1[0][0]']              \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.divide_no_nan[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,563\n",
      "Trainable params: 3,563\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Encoder\n",
    "encoder_input = Input(shape=(X_train.shape[1],))  \n",
    "\n",
    "x = Dense(64, activation='relu')(encoder_input)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "latent = Dense(2,activation='relu')(x)\n",
    "\n",
    "encoded = Model(encoder_input,latent,name='encoded')\n",
    "encoded.summary()\n",
    "\n",
    "# This is the decoder\n",
    "x = Dense(64,activation='relu')(latent)\n",
    "rec = Dense(9,activation='linear')(x)\n",
    "\n",
    "decoded = Model(latent,rec,name='decoded')\n",
    "decoded.summary()\n",
    "\n",
    "decoder_output = decoded(encoded(encoder_input))\n",
    "#Autoencoder Model\n",
    "autoencoder = Model(encoder_input,decoder_output)\n",
    "#Reconstruction loss using Mean squared error of input and decoded output\n",
    "reconstruction_loss = tf.keras.losses.MeanSquaredError()(encoder_input, decoder_output)\n",
    "autoencoder.add_loss(reconstruction_loss)\n",
    "autoencoder.compile(optimizer='adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rus5SlEoCJut",
    "outputId": "d8314b1a-4249-41c4-bc47-4a65ec87d7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1228/1228 [==============================] - 4s 3ms/step - loss: 0.0525 - val_loss: 0.0038\n",
      "Epoch 2/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 3/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 4/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 5/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 6/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 7/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 8/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 11/100\n",
      "1228/1228 [==============================] - 5s 4ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 12/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 13/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 14/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 15/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 16/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 17/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 18/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 19/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 20/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 21/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 22/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 23/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 24/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 25/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 26/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 27/100\n",
      "1228/1228 [==============================] - 4s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 28/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 29/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 30/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 31/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 32/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 34/100\n",
      "1228/1228 [==============================] - 4s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 35/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 36/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 37/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 38/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 39/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 40/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 41/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 42/100\n",
      "1228/1228 [==============================] - 5s 4ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 43/100\n",
      "1228/1228 [==============================] - 4s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 44/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 45/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 46/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 47/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 48/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 49/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 50/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 51/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 52/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 53/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 54/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 55/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 56/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 57/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 58/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 59/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 60/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 61/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 62/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 63/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 64/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 65/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 66/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 67/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 68/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 69/100\n",
      "1228/1228 [==============================] - 4s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 70/100\n",
      "1228/1228 [==============================] - 4s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 71/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 72/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 73/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 74/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 75/100\n",
      "1228/1228 [==============================] - 4s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 76/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 77/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 78/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 79/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 80/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 81/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 82/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 83/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 84/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 85/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 86/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 87/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 88/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 89/100\n",
      "1228/1228 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 90/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 91/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 92/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 93/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 94/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 95/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 96/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 97/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 98/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 99/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 100/100\n",
      "1228/1228 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "# Train the model, this can take some time\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "#Array of loss values\n",
    "loss_values = history.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9C2kqNQsXPA"
   },
   "source": [
    "**Task 3: anomaly detection**\n",
    "\n",
    "From the histogram of the reconstruction error decide what the cutoff should be applied to distinguish anomalies from valid samples, given that the anomaly rate is ~7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "09thlCA2BH7J",
    "outputId": "cfc31eb7-7aa6-4d22-b8ac-deeb0881352f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold is 0.009887321985351763\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions from our AutoEncoder model for the training dataset\n",
    "predictions = autoencoder.predict(X_test)\n",
    "\n",
    "# calculate the mean squared error for each sample\n",
    "mse = ((X_test - predictions) ** 2).mean(axis=1)\n",
    "plt.hist(mse, bins=100)\n",
    "plt.show()\n",
    "# sort the mse in descending order\n",
    "mse_sorted = sorted(mse, reverse=True)\n",
    "# calculate the index of the threshold value\n",
    "threshold_index = int(len(mse_sorted) * 0.07)\n",
    "\n",
    "# set the threshold to the value at the threshold index\n",
    "threshold = mse_sorted[threshold_index]\n",
    "print(f'threshold is {threshold}')\n",
    "# identify the samples that have a mse greater than the threshold \n",
    "anomalies = X_test[mse > threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NZ2WMDLsXPA"
   },
   "source": [
    "### Post (complete by Monday 30/01/23)\n",
    "\n",
    "Post your solution to Tasks 1-3 in notebook form. If you have not completed all the tasks then that is acceptable. The purpose is to get feedback from others in the group, so if you have only a basic outline then you may get ideas about how to proceed and also examples from others in your group.\n",
    "\n",
    "No posts should refer to Task 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Gzqe5WXsXPA"
   },
   "source": [
    "### Respond (complete by Wednesday 01/02/23)\n",
    "\n",
    "If you feel you can provide useful advise then respond to another member of the group through the appropriate forum. Responses should be respectful and offer some sort of advise. Try and avoid clogging the forums with support or thank you messages.\n",
    "\n",
    "In reviewing others code you will discover different ways to tackle the same problem. It is acceptable to copy parts of others code. However whole scale copying from another notebook is not acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WipL-6rFsXPB"
   },
   "source": [
    "Grading guidelines for the forum posts: Weight [2/7]\n",
    "\n",
    "**Beginning [0-8]:** Respectful posts of minor value. Significant number of posts without valuable contributions and/or without well-considered questions. Posts about task 4 in contravention of intructions.\n",
    "\n",
    "**Developing [9-12]:** At least 1 post  exceeding Beginning level with respectful suggestion or thought provoking question. Most posts contain valuable contributions or well-considered questions.\n",
    "\n",
    "**Advancing [13-16]:** At least 2 posts: 1 equal to or exceeding Beginning level;  1 with respectful and sound contribution highlighting mistakes or alternative approaches.\n",
    "\n",
    "**Accomplished [17-20]:** At least 3 posts: 2 equal to or exceeding Accomplished level; 1 with respectful contribution of significant value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rpJZSFrsXPB"
   },
   "source": [
    "### Task 4: VAE (completed by Sunday 05/02/23)\n",
    "\n",
    "This task is a individual task and should **not** to be uploaded to GitHub. No direct support should be given via the forums, although comments about progress or results are allowed. Marks will be deducted if the instructions are not followed (see rubrics). This part should be uploaded directly to Sulis.\n",
    "\n",
    "Change the network to be a VAE. Again determine the optimal cutoff and plot the latent variables. Check how good the cutoffs were by constructing a confusion matrix or generating a classification report. Obviously for this task you need to use the Anom column.\n",
    "\n",
    "**Hint** you can use the model topology from the AE (with the obvious modifications). I found that I had a good model (almost as good and the supervised learning model) when the KL divergence was small. You can print out both the KL divergence and reconstruction loss for each epoch. It can be tricky to train these type of models, so do not be surprised if you do not get a stellar result. What is more important is that you have the correct code to implement the VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fi4NUEv1sXPB"
   },
   "source": [
    "### Final Submission (complete by Sunday 05/02/23)\n",
    "\n",
    "Submit Tasks 1-4 in a single notebook this before the deadline on Sunday.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6__KdhJesXPB"
   },
   "outputs": [],
   "source": [
    "## Add additional code cells to implememt the tasks stated above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy_JL30ksXPC"
   },
   "source": [
    "## Reflection\n",
    "\n",
    "There are no specific marks allocated for a reflection. However due consideration will be given if pertinent comments or valuable insights are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDhYwGNzsXPC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
